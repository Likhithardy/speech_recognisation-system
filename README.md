TEXT SUMMARIZATION TOOL (TASK 2)

COMPANY: CODTECH IT SOLUTIONS

NAME: NAGURI LIKHITHA REDDY

INTERN ID: CT04DN1391DOMAIN: ARTIFICIAL INTELLIGENCE

DURATION: 4 WEEEKS

MENTOR: NEELA SANTOSH

DESCRIPTION:As part of my internship at CODTECH, I was assigned a hands-on project to build a Speech Recognition System—a basic yet functional speech-to-text tool that leverages modern Natural Language Processing (NLP) and audio processing techniques. The aim of this task was to develop a Python-based system that can accurately transcribe short audio clips into readable text using pre-trained models. This project showcases the integration of artificial intelligence with real-world voice input, a technology widely used in applications such as virtual assistants, voice search, automated transcription services, and accessibility tools.To accomplish this, I utilized Python programming due to its vast support for data science and AI-related libraries. I used the SpeechRecognition library, which is a powerful and user-friendly toolkit for performing speech recognition in Python. It supports multiple recognition engines, including Google Web Speech API, CMU Sphinx, and others. For more advanced use cases and higher accuracy, I explored Wav2Vec 2.0, a cutting-edge deep learning model developed by Facebook AI, which provides impressive results in speech-to-text transcription tasks. Wav2Vec 2.0 is part of the Hugging Face Transformers ecosystem, making it convenient to use with pre-trained models for rapid development.The system workflow begins by recording or loading a short audio file, typically in WAV format. Using the SpeechRecognition library, the audio is processed and then converted into text by invoking a recognizer engine. For example, Google’s Web Speech API can be accessed easily by writing just a few lines of code, allowing the system to return transcribed output in seconds. For higher fidelity transcription or offline functionality, I implemented the Wav2Vec 2.0 model using the Transformers pipeline. This involved loading the pre-trained model and tokenizer, converting the audio waveform into tensors using torchaudio, and feeding it into the model to get a highly accurate transcript.The editor platform I used for this project was Visual Studio Code (VS Code). It is a popular and versatile Integrated Development Environment (IDE) ideal for Python development. With features like syntax highlighting, integrated terminal, extensions for Python and Jupyter support, and easy debugging tools, VS Code significantly streamlined the development process. I also used the terminal to install and manage Python packages using pip, and to test scripts in a controlled environment.The Speech Recognition System developed here has wide-ranging applications. In the education sector, it can help students with note-taking by transcribing lectures. In journalism, reporters can use it to convert interviews into text. In customer service, businesses can use it to log voice conversations automatically. It is also extremely useful for accessibility, enabling individuals with hearing or motor impairments to interact with digital systems more effectively. Moreover, it can serve as a backend for virtual assistants, voice-controlled IoT devices, and real-time translation systems.Overall, this project has been an enriching experience, enabling me to gain practical insights into voice processing and deep learning-based speech recognition. It not only sharpened my Python programming skills but also introduced me to real-world AI applications that are shaping the future of human-computer interaction.
